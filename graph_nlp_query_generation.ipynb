{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2qn2xtcFnsjW93w9OjjlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejjus/movie-graph-nlp-chatbot/blob/main/graph_nlp_query_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "!pip install -q neo4j-driver\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCsmUU8gthGS",
        "outputId": "81de5455-14ef-47a9-889a-12fef60882a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.3.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google-generativeai) (1.22.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.61.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.59.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for neo4j-driver (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.6/381.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w8UzOG7y3NX"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as palm\n",
        "import base64\n",
        "import json\n",
        "import gradio as gr\n",
        "from neo4j import GraphDatabase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "palm.configure(api_key = userdata.get(\"palm_api_key\"))"
      ],
      "metadata": {
        "id": "71zwQhwh0V76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(input):\n",
        "\n",
        "  defaults = {\n",
        "    'model': 'models/text-bison-001',\n",
        "    'temperature': 0.7,\n",
        "    'candidate_count': 1,\n",
        "    'top_k': 40,\n",
        "    'top_p': 0.95,\n",
        "    'max_output_tokens': 1024,\n",
        "    'stop_sequences': [],\n",
        "    'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
        "  }\n",
        "\n",
        "  prompt = f\"\"\"You are an expert in converting English questions to Neo4j Cypher Graph code! The Graph has following Node Labels - Movie, Person! the Movie Node has the following properties released, tagline, title. The Person node has properties such as name & born. The Neo4j Graph has the following Relationship types ACTED_IN, DIRECTED, FOLLOWS, PRODUCED, REVIEWED, WROTE!\n",
        "\n",
        "  All relationships ACTED_IN, DIRECTED, FOLLOWS, PRODUCED, REVIEWED, WROTE start from Person to Movie and not the other way around.\n",
        "\n",
        "  For example,\n",
        "  Example 1 - List down 5 movies that released after the year 2000, the Cypher command will be something like this\n",
        "  ``` MATCH (m:Movie)\n",
        "  WHERE m.released > 2000\n",
        "  RETURN m LIMIT 5\n",
        "  ```\n",
        "\n",
        "  Example 2 - Get all the people who acted in a movie that was released after 2010.\n",
        "  ```\n",
        "  MATCH (p:Person)-[r:ACTED_IN]->(m:Movie)\n",
        "  WHERE m.released > 2010\n",
        "  RETURN p,r,m\n",
        "  ```\n",
        "\n",
        "  Example 3 - Name the Director of the movie Apollo 13?\n",
        "  ```\n",
        "  MATCH (m:Movie)<-[:DIRECTED]-(p:Person)\n",
        "  WHERE m.title = 'Apollo';\n",
        "  RETURN p.name\n",
        "  ```\n",
        "\n",
        "  Do not include ``` and \\n in the output\n",
        "\n",
        "  {input}\"\"\"\n",
        "  response = palm.generate_text(**defaults,prompt=prompt)\n",
        "\n",
        "  return response.result"
      ],
      "metadata": {
        "id": "H0eTT6sC09eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_answer(\"Which movie did Emil Eifrem act in?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z04979ei2RxY",
        "outputId": "6c3efe0c-cff0-44dd-e94d-60c217025516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MATCH (p:Person {name: \"Emil Eifrem\"})-[r:ACTED_IN]->(m:Movie) RETURN m.title'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver = GraphDatabase.driver(\"neo4j+s://a18c3962.databases.neo4j.io\",\n",
        "                              auth=(\"neo4j\",\n",
        "                                    \"y2-2WQTJ_nNdqnzJou0R2rAopWCQmDA6IhB0yo1gDYo\"))"
      ],
      "metadata": {
        "id": "S2hwkjor2WlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "f_DzHL8v2o9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_query_and_return_key(input_query_result):\n",
        "    slash_n_pattern = r'[ \\n]+'\n",
        "    ret_pattern = r'RETURN\\s+(.*)'\n",
        "    replacement = ' '\n",
        "\n",
        "    cleaned_query = re.sub(slash_n_pattern, replacement, input_query_result)\n",
        "    if cleaned_query:\n",
        "        match = re.search(ret_pattern, cleaned_query)\n",
        "        if match:\n",
        "            extracted_string = match.group(1)\n",
        "        else:\n",
        "            extracted_string = \"\"\n",
        "    return cleaned_query, extracted_string"
      ],
      "metadata": {
        "id": "MJue_Kip3BHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_query_and_return_key(get_answer(\"Who were the actors in the movie V for Vendetta\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SUIQufa3FYC",
        "outputId": "5b98198a-3199-4995-e0a9-82b76815b6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"MATCH (p:Person)-[r:ACTED_IN]->(m:Movie) WHERE m.title = 'V for Vendetta' RETURN p.name\",\n",
              " 'p.name')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_names_with_ampersand(names):\n",
        "    if len(names) == 0:\n",
        "        return \"\"\n",
        "    elif len(names) == 1:\n",
        "        return names[0]\n",
        "    else:\n",
        "        formatted_names = \", \".join(names[:-1]) + \" & \" + names[-1]\n",
        "        return formatted_names"
      ],
      "metadata": {
        "id": "tQRcOls73RL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_names_with_ampersand([\"Sachin\",\"Virat\",\"Rahul\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6m9ZLpN43nd5",
        "outputId": "ee06229b-cd27-4f37-c29d-842a5a05adeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sachin, Virat & Rahul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cypher_on_neo4j(inp_query, inp_key):\n",
        "    out_list = []\n",
        "    with driver.session() as session:\n",
        "        result = session.run(inp_query)\n",
        "        for record in result:\n",
        "            out_list.append(record[inp_key])\n",
        "    driver.close()\n",
        "    if len(out_list) > 1:\n",
        "        return format_names_with_ampersand(out_list)\n",
        "    else:\n",
        "        return out_list[0]"
      ],
      "metadata": {
        "id": "AdQyRlwd3r-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_1, string_1 = extract_query_and_return_key(get_answer(\"Who were the actors in the movie V for Vendetta\"))\n",
        "\n",
        "run_cypher_on_neo4j (query_1, string_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_6Mej9BM4CDf",
        "outputId": "64ec4080-2d36-449b-8e27-c8ae6f664175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'John Hurt, Stephen Rea, Natalie Portman, Hugo Weaving & Ben Miles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_exec_cypher(input_query):\n",
        "    gen_query, gen_key = extract_query_and_return_key(get_answer(input_query))\n",
        "    return run_cypher_on_neo4j(gen_query, gen_key)"
      ],
      "metadata": {
        "id": "bzxt9fs84Fix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = str(generate_and_exec_cypher(input))\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ],
      "metadata": {
        "id": "hFDnLM_S4Jho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn = chatbot,\n",
        "             inputs = [\"text\",'state'],\n",
        "             outputs = [\"chatbot\",'state']).launch(debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RzzpTDOq4Onc",
        "outputId": "e3eec4a0-ff40-4048-f94a-419ef21f7ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://1306873435f7f2381d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://1306873435f7f2381d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-6d234cc3d37d>:3: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n"
          ]
        }
      ]
    }
  ]
}