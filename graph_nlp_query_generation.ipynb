{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMSACxsSxgNv/VU/BG9JE8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejjus/movie-graph-nlp-chatbot/blob/main/graph_nlp_query_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0w8UzOG7y3NX"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as palm\n",
        "import base64\n",
        "import json\n",
        "import gradio as gr\n",
        "from neo4j import GraphDatabase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "palm.configure(api_key = userdata.get(\"palm_api_key\"))"
      ],
      "metadata": {
        "id": "71zwQhwh0V76"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(input):\n",
        "\n",
        "  defaults = {\n",
        "    'model': 'models/text-bison-001',\n",
        "    'temperature': 0.7,\n",
        "    'candidate_count': 1,\n",
        "    'top_k': 40,\n",
        "    'top_p': 0.95,\n",
        "    'max_output_tokens': 1024,\n",
        "    'stop_sequences': [],\n",
        "    'safety_settings': [{\"category\":\"HARM_CATEGORY_DEROGATORY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_TOXICITY\",\"threshold\":1},{\"category\":\"HARM_CATEGORY_VIOLENCE\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_SEXUAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_MEDICAL\",\"threshold\":2},{\"category\":\"HARM_CATEGORY_DANGEROUS\",\"threshold\":2}],\n",
        "  }\n",
        "\n",
        "  prompt = f\"\"\"You are an expert in converting English questions to Neo4j Cypher Graph code! The Graph has following Node Labels - Movie, Person! the Movie Node has the following properties released, tagline, title. The Person node has properties such as name & born. The Neo4j Graph has the following Relationship types ACTED_IN, DIRECTED, FOLLOWS, PRODUCED, REVIEWED, WROTE!\n",
        "\n",
        "  All relationships ACTED_IN, DIRECTED, FOLLOWS, PRODUCED, REVIEWED, WROTE start from Person to Movie and not the other way around.\n",
        "\n",
        "  For example,\n",
        "  Example 1 - List down 5 movies that released after the year 2000, the Cypher command will be something like this\n",
        "  ``` MATCH (m:Movie)\n",
        "  WHERE m.released > 2000\n",
        "  RETURN m LIMIT 5\n",
        "  ```\n",
        "\n",
        "  Example 2 - Get all the people who acted in a movie that was released after 2010.\n",
        "  ```\n",
        "  MATCH (p:Person)-[r:ACTED_IN]->(m:Movie)\n",
        "  WHERE m.released > 2010\n",
        "  RETURN p,r,m\n",
        "  ```\n",
        "\n",
        "  Example 3 - Name the Director of the movie Apollo 13?\n",
        "  ```\n",
        "  MATCH (m:Movie)<-[:DIRECTED]-(p:Person)\n",
        "  WHERE m.title = 'Apollo';\n",
        "  RETURN p.name\n",
        "  ```\n",
        "\n",
        "  Do not include ``` and \\n in the output\n",
        "\n",
        "  {input}\"\"\"\n",
        "  response = palm.generate_text(**defaults,prompt=prompt)\n",
        "\n",
        "  return response.result"
      ],
      "metadata": {
        "id": "H0eTT6sC09eN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_answer(\"Which movie did Emil Eifrem act in?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z04979ei2RxY",
        "outputId": "fd9717a4-511c-4741-806b-739d099e4f33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"MATCH (p:Person {name:'Emil Eifrem'})-[a:ACTED_IN]->(m:Movie) RETURN m.title\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver = GraphDatabase.driver(\"neo4j+s://a18c3962.databases.neo4j.io\",\n",
        "                              auth=(\"neo4j\",\n",
        "                                    \"y2-2WQTJ_nNdqnzJou0R2rAopWCQmDA6IhB0yo1gDYo\"))"
      ],
      "metadata": {
        "id": "S2hwkjor2WlR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "f_DzHL8v2o9p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_query_and_return_key(input_query_result):\n",
        "    slash_n_pattern = r'[ \\n]+'\n",
        "    ret_pattern = r'RETURN\\s+(.*)'\n",
        "    replacement = ' '\n",
        "\n",
        "    cleaned_query = re.sub(slash_n_pattern, replacement, input_query_result)\n",
        "    if cleaned_query:\n",
        "        match = re.search(ret_pattern, cleaned_query)\n",
        "        if match:\n",
        "            extracted_string = match.group(1)\n",
        "        else:\n",
        "            extracted_string = \"\"\n",
        "    return cleaned_query, extracted_string"
      ],
      "metadata": {
        "id": "MJue_Kip3BHA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_query_and_return_key(get_answer(\"Who were the actors in the movie V for Vendetta\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SUIQufa3FYC",
        "outputId": "3906cf31-e45c-4d09-f9fb-d781a0d618d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"MATCH (p:Person)-[r:ACTED_IN]->(m:Movie) WHERE m.title = 'V for Vendetta' RETURN p.name\",\n",
              " 'p.name')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_names_with_ampersand(names):\n",
        "    if len(names) == 0:\n",
        "        return \"\"\n",
        "    elif len(names) == 1:\n",
        "        return names[0]\n",
        "    else:\n",
        "        formatted_names = \", \".join(names[:-1]) + \" & \" + names[-1]\n",
        "        return formatted_names"
      ],
      "metadata": {
        "id": "tQRcOls73RL2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_names_with_ampersand([\"Sachin\",\"Virat\",\"Rahul\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6m9ZLpN43nd5",
        "outputId": "80c10724-d836-4279-a9ff-c5e669675407"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sachin, Virat & Rahul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cypher_on_neo4j(inp_query, inp_key):\n",
        "    out_list = []\n",
        "    with driver.session() as session:\n",
        "        result = session.run(inp_query)\n",
        "        for record in result:\n",
        "            out_list.append(record[inp_key])\n",
        "    driver.close()\n",
        "    if len(out_list) > 1:\n",
        "        return format_names_with_ampersand(out_list)\n",
        "    else:\n",
        "        return out_list[0]"
      ],
      "metadata": {
        "id": "AdQyRlwd3r-U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_1, string_1 = extract_query_and_return_key(get_answer(\"Who were the actors in the movie V for Vendetta\"))\n",
        "\n",
        "run_cypher_on_neo4j (query_1, string_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_6Mej9BM4CDf",
        "outputId": "83df7461-5365-4727-b563-809dfb7f6713"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'John Hurt, Stephen Rea, Natalie Portman, Hugo Weaving & Ben Miles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_exec_cypher(input_query):\n",
        "    gen_query, gen_key = extract_query_and_return_key(get_answer(input_query))\n",
        "    return run_cypher_on_neo4j(gen_query, gen_key)"
      ],
      "metadata": {
        "id": "bzxt9fs84Fix"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = str(generate_and_exec_cypher(input))\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ],
      "metadata": {
        "id": "hFDnLM_S4Jho"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn = chatbot,\n",
        "             inputs = [\"text\",'state'],\n",
        "             outputs = [\"chatbot\",'state']).launch(debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RzzpTDOq4Onc",
        "outputId": "61454ba4-dbfc-4c82-846d-f85a6ab1b95e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://26b289c330270f2770.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://26b289c330270f2770.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-6d234cc3d37d>:3: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 9, in run_cypher_on_neo4j\n",
            "    return format_names_with_ampersand(out_list)\n",
            "  File \"<ipython-input-10-a3892f9f0070>\", line 7, in format_names_with_ampersand\n",
            "    formatted_names = \", \".join(names[:-1]) + \" & \" + names[-1]\n",
            "TypeError: sequence item 0: expected str instance, Node found\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 9, in run_cypher_on_neo4j\n",
            "    return format_names_with_ampersand(out_list)\n",
            "  File \"<ipython-input-10-a3892f9f0070>\", line 7, in format_names_with_ampersand\n",
            "    formatted_names = \", \".join(names[:-1]) + \" & \" + names[-1]\n",
            "TypeError: sequence item 0: expected str instance, Node found\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 673, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-15-125151d1326a>\", line 2, in chatbot\n",
            "    output = str(generate_and_exec_cypher(input))\n",
            "  File \"<ipython-input-14-694492ab05d0>\", line 3, in generate_and_exec_cypher\n",
            "    return run_cypher_on_neo4j(gen_query, gen_key)\n",
            "  File \"<ipython-input-12-6d234cc3d37d>\", line 11, in run_cypher_on_neo4j\n",
            "    return out_list[0]\n",
            "IndexError: list index out of range\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://26b289c330270f2770.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9okieuj4Q93"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}